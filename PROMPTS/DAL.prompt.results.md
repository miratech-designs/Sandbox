Using .net10, I want to create a custom generic data access layer using only native libraries that will connect exclusively to MSSQL data servers.
the project will eventually be turned into a nuget package that will be the starting block of web and console applications.

It is fantastic that you are looking to build a foundational, "bare-metal" library for .NET 10. Using .NET 10 (the latest Long Term Support release) with only native libraries (Microsoft.Data.SqlClient) is an excellent way to ensure high performance, low memory overhead, and zero third-party dependencies (like Entity Framework or Dapper).
Here is a complete guide and implementation for your Generic Data Access Layer (DAL).
Overview of the Solution
We will build a generic, reflection-based repository that maps SQL results to C# objects automatically.
1. Core Library: A Generic Repository class that handles CRUD operations using Microsoft.Data.SqlClient.
2. Mapping: A lightweight mapping system (using Reflection) to convert SqlDataReader rows into strong types (T).
3. Dependency Injection: Extensions to easily add this to the DI container for Web/API apps.
4. Packaging: Instructions on how to pack this as a generic NuGet library.

1. The Project File (.csproj)
First, create a Class Library project. We will target .net10.0 and include the only required native dependency.

<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFramework>net10.0</TargetFramework>
    <ImplicitUsings>enable</ImplicitUsings>
    <Nullable>enable</Nullable>
    <Version>1.0.0</Version>
    <Title>NativeSql.DataAccess</Title>
    <Description>A lightweight, generic DAL for MSSQL using native .NET 10 libraries.</Description>
    <PackageId>MyCompany.NativeSql</PackageId>
    <Authors>YourName</Authors>
    <GeneratePackageOnBuild>true</GeneratePackageOnBuild>
  </PropertyGroup>

  <ItemGroup>
    <PackageReference Include="Microsoft.Data.SqlClient" Version="6.0.1" />
  </ItemGroup>

</Project>


2. The Generic Repository Code
We will create a base abstract class BaseRepository<T> that handles the connections and basic CRUD commands.
BaseRepository.cs
This uses standard ADO.NET but wraps it in a generic interface. It assumes your database tables match your class names and column names match property names (Convention over Configuration).

using Microsoft.Data.SqlClient;
using System.Data;
using System.Reflection;

namespace NativeSql.DataAccess;

public abstract class BaseRepository<T> where T : new()
{
    private readonly string _connectionString;

    protected BaseRepository(string connectionString)
    {
        _connectionString = connectionString;
    }

    // Helper to get an open connection
    protected async Task<SqlConnection> CreateConnectionAsync()
    {
        var connection = new SqlConnection(_connectionString);
        await connection.OpenAsync();
        return connection;
    }

    // Generic Get All
    public async Task<IEnumerable<T>> GetAllAsync(string tableName)
    {
        var list = new List<T>();

        using var connection = await CreateConnectionAsync();
        using var command = new SqlCommand($"SELECT * FROM [{tableName}]", connection);
        using var reader = await command.ExecuteReaderAsync();

        while (await reader.ReadAsync())
        {
            list.Add(MapReaderToObject(reader));
        }

        return list;
    }

    // Generic Get By Id
    public async Task<T?> GetByIdAsync(string tableName, string pkColumnName, object id)
    {
        using var connection = await CreateConnectionAsync();
        // Parameterized query to prevent SQL Injection
        var query = $"SELECT TOP 1 * FROM [{tableName}] WHERE [{pkColumnName}] = @Id";
        
        using var command = new SqlCommand(query, connection);
        command.Parameters.AddWithValue("@Id", id);

        using var reader = await command.ExecuteReaderAsync();
        
        if (await reader.ReadAsync())
        {
            return MapReaderToObject(reader);
        }

        return default;
    }

    // Generic Execute (Insert/Update/Delete)
    protected async Task<int> ExecuteNonQueryAsync(string sql, Dictionary<string, object> parameters)
    {
        using var connection = await CreateConnectionAsync();
        using var command = new SqlCommand(sql, connection);

        foreach (var param in parameters)
        {
            // Handle nulls gracefully for SQL
            command.Parameters.AddWithValue(param.Key, param.Value ?? DBNull.Value);
        }

        return await command.ExecuteNonQueryAsync();
    }

    // --- The "Magic" Mapper (Native Reflection) ---
    // Maps a SqlDataReader row to a generic Object T
    private T MapReaderToObject(SqlDataReader reader)
    {
        var item = new T();
        var properties = typeof(T).GetProperties();

        foreach (var prop in properties)
        {
            // Only map if the column exists in the result set
            if (!ColumnExists(reader, prop.Name)) continue;

            var value = reader[prop.Name];

            if (value != DBNull.Value)
            {
                prop.SetValue(item, value);
            }
        }

        return item;
    }

    // Helper to check if column exists in reader
    private bool ColumnExists(SqlDataReader reader, string columnName)
    {
        for (int i = 0; i < reader.FieldCount; i++)
        {
            if (reader.GetName(i).Equals(columnName, StringComparison.OrdinalIgnoreCase))
            {
                return true;
            }
        }
        return false;
    }
}

3. Implementing for a Specific Entity (The Usage)
When the user of your package creates an application, they will inherit from your BaseRepository.
Example Entity:
public class User
{
    public int Id { get; set; }
    public string FirstName { get; set; } = string.Empty;
    public string LastName { get; set; } = string.Empty;
    public DateTime CreatedDate { get; set; }
}

Example Repository Implementation:

public class UserRepository : BaseRepository<User>
{
    public UserRepository(string connectionString) : base(connectionString) { }

    public async Task<IEnumerable<User>> GetUsersAsync() 
    {
        return await GetAllAsync("Users");
    }

    public async Task<User?> GetUserByIdAsync(int id)
    {
        return await GetByIdAsync("Users", "Id", id);
    }

    public async Task AddUserAsync(User user)
    {
        var sql = "INSERT INTO Users (FirstName, LastName, CreatedDate) VALUES (@Fn, @Ln, @Dt)";
        var parameters = new Dictionary<string, object>
        {
            { "@Fn", user.FirstName },
            { "@Ln", user.LastName },
            { "@Dt", user.CreatedDate }
        };

        await ExecuteNonQueryAsync(sql, parameters);
    }
}

4. Web Application Support (Dependency Injection)
To make this a truly modern NuGet package for Web APIs, you should include an extension method to make registration easy in Program.cs.
Create a file named ServiceCollectionExtensions.cs in your library:

using Microsoft.Extensions.DependencyInjection;

namespace NativeSql.DataAccess;

public static class ServiceCollectionExtensions
{
    // Defines a standard way to register the Connection String
    public static IServiceCollection AddNativeSql(this IServiceCollection services, string connectionString)
    {
        // Register the connection string as a singleton so repositories can inject it
        services.AddSingleton(new ConnectionStringWrapper(connectionString));
        return services;
    }
}

// Simple wrapper to allow injecting a string cleanly
public record ConnectionStringWrapper(string Value);

Note: You will need to slightly adjust the BaseRepository constructor to accept this wrapper for DI support:

// Updated Constructor in BaseRepository
protected BaseRepository(ConnectionStringWrapper connectionStringWrapper)
{
    _connectionString = connectionStringWrapper.Value;
}

5. Implementation Instructions
Here is how you or your users would consume this package in different project types.


A. In a .NET 10 Web API (Program.cs)

using NativeSql.DataAccess;

var builder = WebApplication.CreateBuilder(args);

// 1. Register the Native SQL Layer
var connString = builder.Configuration.GetConnectionString("DefaultConnection");
builder.Services.AddNativeSql(connString!);

// 2. Register your specific repositories
builder.Services.AddScoped<UserRepository>();

var app = builder.Build();

// 3. Use in an endpoint
app.MapGet("/users", async (UserRepository repo) => 
{
    return await repo.GetUsersAsync();
});

app.Run();


B. In a Console Application
using NativeSql.DataAccess;

// Manual instantiation
var connStringWrapper = new ConnectionStringWrapper("Server=.;Database=MyDb;Trusted_Connection=True;TrustServerCertificate=True;");
var userRepo = new UserRepository(connStringWrapper);

Console.WriteLine("Fetching users...");
var users = await userRepo.GetUsersAsync();

foreach(var u in users)
{
    Console.WriteLine($"{u.FirstName} {u.LastName}");
}

Summary of Development Steps
1. Create Project: Create a .NET 10 Class Library.
2. Install Dependency: Add Microsoft.Data.SqlClient.
3. Implement Core: Copy the BaseRepository<T> code.
4. Implement DI Helpers: Copy the ServiceCollectionExtensions.
5. Pack: Run dotnet pack -c Release. This will generate a .nupkg file in your bin/Release folder.
6. Publish: Upload that .nupkg file to NuGet.org or your private feed.

--------
Can you provide extension methods to provide fluent syntax for executing all types of sql commands

This is a great evolution for your library. A fluent interface (Method Chaining) makes the code much more readable and reduces the boilerplate of manually setting up SqlCommand objects.
To achieve this using only native libraries, we will implement the Builder Pattern.
Here is the implementation plan:
1. EntityMapper: Extract the reflection logic into a static helper so it can be reused.
2. SqlFluentBuilder: A wrapper class that builds the command and parameters step-by-step.
3. DbExtensions: Extension methods to attach this functionality to SqlConnection.
1. The Shared Mapper (EntityMapper.cs)
We need to move the mapping logic out of the repository so the fluent builder can use it.

using Microsoft.Data.SqlClient;
using System.Reflection;

namespace NativeSql.DataAccess;

internal static class EntityMapper
{
    public static T Map<T>(SqlDataReader reader) where T : new()
    {
        var item = new T();
        var properties = typeof(T).GetProperties();

        // Optimization: Cache column names in a HashSet for fast lookup
        var columns = new HashSet<string>(StringComparer.OrdinalIgnoreCase);
        for (int i = 0; i < reader.FieldCount; i++)
        {
            columns.Add(reader.GetName(i));
        }

        foreach (var prop in properties)
        {
            if (columns.Contains(prop.Name))
            {
                var value = reader[prop.Name];
                if (value != DBNull.Value)
                {
                    prop.SetValue(item, value);
                }
            }
        }

        return item;
    }
}

2. The Fluent Builder (SqlFluentBuilder.cs)
This class holds the state of the command (SQL text, parameters, type) until you call an "Execute" method.

using Microsoft.Data.SqlClient;
using System.Data;

namespace NativeSql.DataAccess;

public class SqlFluentBuilder
{
    private readonly SqlConnection _connection;
    private readonly SqlCommand _command;
    private SqlTransaction? _transaction;

    public SqlFluentBuilder(SqlConnection connection, string sqlText)
    {
        _connection = connection;
        _command = new SqlCommand(sqlText, connection);
    }

    // --- Configuration Methods (Chainable) ---

    public SqlFluentBuilder WithParameter(string name, object? value)
    {
        // Native handling of C# nulls to SQL DBNull
        _command.Parameters.AddWithValue(name, value ?? DBNull.Value);
        return this;
    }

    public SqlFluentBuilder WithParameters(Dictionary<string, object?> parameters)
    {
        foreach (var param in parameters)
        {
            WithParameter(param.Key, param.Value);
        }
        return this;
    }

    public SqlFluentBuilder AsStoredProcedure()
    {
        _command.CommandType = CommandType.StoredProcedure;
        return this;
    }

    public SqlFluentBuilder WithTimeout(int seconds)
    {
        _command.CommandTimeout = seconds;
        return this;
    }

    public SqlFluentBuilder WithTransaction(SqlTransaction transaction)
    {
        _transaction = transaction;
        _command.Transaction = transaction;
        return this;
    }

    // --- Execution Methods (Terminals) ---

    // 1. Execute NonQuery (INSERT, UPDATE, DELETE)
    public async Task<int> ExecuteAsync()
    {
        await EnsureConnectionOpenAsync();
        return await _command.ExecuteNonQueryAsync();
    }

    // 2. Execute Scalar (Count, Getting IDs)
    public async Task<T?> ExecuteScalarAsync<T>()
    {
        await EnsureConnectionOpenAsync();
        var result = await _command.ExecuteScalarAsync();

        if (result == null || result == DBNull.Value)
            return default;

        return (T)Convert.ChangeType(result, typeof(T));
    }

    // 3. Execute List (SELECT * FROM ...)
    public async Task<IEnumerable<T>> QueryAsync<T>() where T : new()
    {
        await EnsureConnectionOpenAsync();
        var list = new List<T>();

        using var reader = await _command.ExecuteReaderAsync();
        while (await reader.ReadAsync())
        {
            list.Add(EntityMapper.Map<T>(reader));
        }

        return list;
    }

    // 4. Execute Single (SELECT TOP 1 ...)
    public async Task<T?> QuerySingleAsync<T>() where T : new()
    {
        await EnsureConnectionOpenAsync();
        
        using var reader = await _command.ExecuteReaderAsync();
        if (await reader.ReadAsync())
        {
            return EntityMapper.Map<T>(reader);
        }

        return default;
    }

    // Helper to ensure connection is open before execution
    private async Task EnsureConnectionOpenAsync()
    {
        if (_connection.State == ConnectionState.Closed)
        {
            await _connection.OpenAsync();
        }
    }
}

3. The Extensions (DbExtensions.cs)
This is the "syntax sugar" that allows you to write .Sql("...") directly on the connection object.

using Microsoft.Data.SqlClient;

namespace NativeSql.DataAccess;

public static class DbExtensions
{
    /// <summary>
    /// Starts a Fluent SQL Command
    /// </summary>
    public static SqlFluentBuilder Sql(this SqlConnection connection, string sqlText)
    {
        return new SqlFluentBuilder(connection, sqlText);
    }
}

4. Implementation & Usage Guide
Here is how you use the new Fluent Syntax in your application. Notice how readable the code becomes‚Äîit reads almost like an English sentence.

A. Writing Data (Insert/Update)
using NativeSql.DataAccess;
using Microsoft.Data.SqlClient;

// Assuming you have your connection wrapper or just a new connection
using var conn = new SqlConnection("YourConnectionString...");

// Fluent Insert
await conn.Sql("INSERT INTO Users (FirstName, LastName) VALUES (@fn, @ln)")
          .WithParameter("@fn", "John")
          .WithParameter("@ln", "Doe")
          .ExecuteAsync();


B. Reading a List (Select)
// Automatically maps to List<User>
IEnumerable<User> users = await conn.Sql("SELECT * FROM Users WHERE CreatedDate > @date")
                                    .WithParameter("@date", DateTime.Now.AddDays(-30))
                                    .QueryAsync<User>();

C. Reading a Single Value (Scalar)
// Get a generic type (int, string, bool)
int count = await conn.Sql("SELECT COUNT(*) FROM Users")
                      .ExecuteScalarAsync<int>();

D. Using Stored Procedures
// Calls 'sp_GetUserById' with ID 5
var user = await conn.Sql("sp_GetUserById")
                     .AsStoredProcedure()
                     .WithParameter("@Id", 5)
                     .QuerySingleAsync<User>();

E. Using Transactions

await conn.OpenAsync();
using var transaction = conn.BeginTransaction();

try 
{
    await conn.Sql("INSERT INTO Logs (Message) VALUES (@msg)")
              .WithTransaction(transaction)
              .WithParameter("@msg", "Step 1 Complete")
              .ExecuteAsync();

    await conn.Sql("DELETE FROM TempTable")
              .WithTransaction(transaction)
              .ExecuteAsync();

    transaction.Commit();
}
catch
{
    transaction.Rollback();
}

Integration with your Repository
You can now update your BaseRepository to use this syntax internally, making it much cleaner to maintain:

// Inside BaseRepository<T>
public async Task<T?> GetByIdAsync(object id)
{
    using var conn = await CreateConnectionAsync();
    
    // Very clean implementation!
    return await conn.Sql($"SELECT * FROM {typeof(T).Name} WHERE Id = @id")
                     .WithParameter("@id", id)
                     .QuerySingleAsync<T>();
}
-------
Great choice. Implementing IAsyncEnumerable<T> is a game-changer for performance.
When you use QueryAsync<T> (which returns a List<T> or IEnumerable<T>), the application must wait for the database to return all rows, allocate memory for all objects, and only then can you start processing. If you query 100,000 rows, your RAM usage spikes massively.
With Streaming (IAsyncEnumerable), you act like a conveyor belt: you grab one row, map it, process it, discard it, and then ask for the next.
1. Update SqlFluentBuilder.cs
Add the QueryStreamAsync method to your existing builder class.
I will also include CommandBehavior.SequentialAccess. This is a native SQL optimization that tells the driver "I promise to read columns in order." It allows the driver to stream data directly from the network packet without buffering the whole row internally, providing a significant speed boost for large datasets.

// ... inside SqlFluentBuilder class ...

// 5. Execute Stream (IAsyncEnumerable) - The "Conveyor Belt"
public async IAsyncEnumerable<T> QueryStreamAsync<T>() where T : new()
{
    await EnsureConnectionOpenAsync();

    // SequentialAccess optimizes the read for data streams
    // Note: When using SequentialAccess, you technically must read columns in the order they appear in the SQL.
    // Our EntityMapper handles this fairly well, but for maximum speed, ensure your T properties 
    // roughly match the order of columns in your SELECT statement.
    using var reader = await _command.ExecuteReaderAsync(CommandBehavior.SequentialAccess);

    while (await reader.ReadAsync())
    {
        // Yield results one by one. 
        // The database connection remains open and "busy" until this loop finishes.
        yield return EntityMapper.Map<T>(reader);
    }
}

2. How to Implement (The Usage)
Using streaming requires the await foreach syntax introduced in C# 8. This looks like a normal loop, but it awaits every single iteration effectively.
Scenario: Generative AI / CSV Export
Imagine you need to write a CSV file with 1 million transaction records. If you load all 1 million into a List, you might get an OutOfMemoryException.

using NativeSql.DataAccess;
using System.Text;

// 1. Define the query
var builder = connection.Sql("SELECT * FROM LargeTransactionTable");

// 2. Stream the data
// This line does NOT execute the query yet. It prepares the iterator.
var dataStream = builder.QueryStreamAsync<Transaction>();

using var writer = new StreamWriter("output.csv");

// 3. Process row-by-row
await foreach (var transaction in dataStream)
{
    // Only ONE transaction object exists in memory at this specific moment
    var line = $"{transaction.Id},{transaction.Amount},{transaction.Date}";
    await writer.WriteLineAsync(line);
    
    // After this bracket, 'transaction' is eligible for garbage collection immediately.
}

Console.WriteLine("Export complete using minimal RAM.");

3. Important Considerations for Streaming
While powerful, streaming has rules:
1. Connection Locking: While you are inside the await foreach loop, the SqlConnection is busy. You cannot run another query on that specific connection object until the loop finishes.
2. Context Switching: Because await happens every row, there is a tiny CPU overhead for context switching. For small lists (e.g., < 1000 items), standard QueryAsync (List) is often faster. Use Streaming for bulk operations.
3. Exceptions: If an error occurs mid-stream (e.g., network drop on row 500), the await foreach will throw an exception, and the using block in the builder ensures the reader is closed properly.
Summary of Capabilities
Your native library is becoming very powerful. You now have:
‚Ä¢ Crud Operations: Standard Insert/Update/Select.
‚Ä¢ Fluent Syntax: .Sql("...").WithParameter(...)
‚Ä¢ Memory Efficiency: QueryStreamAsync<T> for massive data.
‚Ä¢ Zero 3rd Party Deps: Just raw .NET 10 speed.

Would you like me to implement a "Bulk Insert" feature next? (Standard SQL Inserts are slow for thousands of rows; SqlBulkCopy is the native way to insert 10,000 rows in milliseconds).

This is an essential feature for any production-grade data library.
Standard INSERT statements process rows one by one, generating a massive amount of transaction logs and network chatter. SqlBulkCopy is the native .NET wrapper for the SQL Server Bulk Import API. It streams data directly into table pages, which is often 50x to 100x faster than looping standard inserts.
Since SqlBulkCopy natively requires a DataTable or IDataReader (and not a generic List<T>), we need to build a bridge to convert your generic objects into a format SQL understands.
Here is the implementation.
1. The Helper: Object-to-DataTable Converter
We need a lightweight reflection helper to turn your IEnumerable<T> into a DataTable that SqlBulkCopy can consume.
Add this to your EntityMapper.cs (or a new DataHelper.cs):

using System.Data;
using System.ComponentModel;

namespace NativeSql.DataAccess;

internal static class DataHelper
{
    public static DataTable ToDataTable<T>(IEnumerable<T> data)
    {
        var table = new DataTable();
        
        // 1. Get Properties of T to create columns
        // We ignore properties that can't be mapped (like Lists or complex objects)
        var properties = TypeDescriptor.GetProperties(typeof(T));

        foreach (PropertyDescriptor prop in properties)
        {
            // Use Nullable type if necessary
            table.Columns.Add(prop.Name, Nullable.GetUnderlyingType(prop.PropertyType) ?? prop.PropertyType);
        }

        // 2. Populate Rows
        foreach (T item in data)
        {
            var row = table.NewRow();
            foreach (PropertyDescriptor prop in properties)
            {
                // Handle DBNull safely
                row[prop.Name] = prop.GetValue(item) ?? DBNull.Value;
            }
            table.Rows.Add(row);
        }

        return table;
    }
}

2. The Bulk Extension (DbExtensions.cs)
We will add a BulkInsertAsync extension method. I have designed this to be smart: it automatically maps your C# property names to the SQL column names, so the order of properties in your class doesn't matter.
Update DbExtensions.cs:
// ... existing usings ...
using System.Data;

namespace NativeSql.DataAccess;

public static partial class DbExtensions
{
    // ... existing Sql() method ...

    /// <summary>
    /// Performs a high-performance Bulk Insert.
    /// </summary>
    /// <param name="transaction">Optional: Pass an existing transaction if this is part of a larger unit of work.</param>
    public static async Task BulkInsertAsync<T>(
        this SqlConnection connection, 
        IEnumerable<T> data, 
        string destinationTableName, 
        SqlTransaction? transaction = null)
    {
        // 1. Convert data to format SQL understands
        // Note: For lists > 100k items, implementing IDataReader is better than DataTable (memory-wise),
        // but DataTable is perfect for batches of 1k-50k.
        using var dataTable = DataHelper.ToDataTable(data);

        // 2. Configure Bulk Copy
        // We pass the transaction (if any) into the constructor options
        var options = SqlBulkCopyOptions.CheckConstraints | SqlBulkCopyOptions.FireTriggers;
        
        using var bulkCopy = new SqlBulkCopy(connection, options, transaction);
        
        bulkCopy.DestinationTableName = destinationTableName;
        
        // Optional: Tuning settings
        bulkCopy.BatchSize = 5000; // Send to server in chunks of 5000
        bulkCopy.BulkCopyTimeout = 600; // 10 minutes

        // 3. Map Columns explicitly (Property Name -> Column Name)
        // This ensures that if your Class properties are in a different order than SQL columns, it still works.
        foreach (DataColumn column in dataTable.Columns)
        {
            bulkCopy.ColumnMappings.Add(column.ColumnName, column.ColumnName);
        }

        // 4. Write to Server
        if (connection.State != ConnectionState.Open) await connection.OpenAsync();
        
        await bulkCopy.WriteToServerAsync(dataTable);
    }
}

3. How to Use It
Here is how you can insert 10,000 users in under a second.

using NativeSql.DataAccess;
using Microsoft.Data.SqlClient;

// 1. Generate dummy data
var newUsers = new List<User>();
for(int i = 0; i < 10000; i++)
{
    newUsers.Add(new User 
    { 
        FirstName = $"User{i}", 
        LastName = "Test", 
        CreatedDate = DateTime.Now 
    });
}

using var conn = new SqlConnection("YourConnectionString...");

// 2. Execute Bulk Insert
// Simple, one-line execution
await conn.BulkInsertAsync(newUsers, "Users");

Console.WriteLine("10,000 users inserted.");


4. Advanced Usage: Bulk with Transactions
A common requirement is to delete old data and bulk insert new data as a single atomic operation.


await conn.OpenAsync();
using var trans = conn.BeginTransaction();

try
{
    // Step 1: Delete old data using Fluent SQL
    await conn.Sql("DELETE FROM DailyStats WHERE Date = @dt")
              .WithParameter("@dt", DateTime.Today)
              .WithTransaction(trans)
              .ExecuteAsync();

    // Step 2: Bulk Insert new data within the SAME transaction
    await conn.BulkInsertAsync(statsList, "DailyStats", trans);

    // If we get here, both succeeded
    trans.Commit();
}
catch
{
    // If anything failed, the Delete is undone
    trans.Rollback();
}

Summary of your Native .NET 10 Library
You now have a package that rivals Dapper in features but uses zero dependencies:
1. BaseRepository: For structured architecture.
2. connection.Sql(...): Fluent API for ad-hoc queries.
3. .QueryStreamAsync<T>(): For memory-efficient reading (Select).
4. .BulkInsertAsync<T>(): For high-performance writing (Insert).

------

Would you like to see how to handle "Output Parameters" (e.g., getting the ID back after an Insert) within your Fluent Syntax?

Handling output parameters in a Fluent interface can be tricky because the chain (the fluent syntax) usually ends when you call Execute..., but you need the values after execution.
To solve this gracefully, we will use Action Delegates. This allows you to define "what to do with the value" while you are building the query, but the code inside that action will only run once the database returns the data.
1. Update SqlFluentBuilder.cs
We need to add a mechanism to store these "callbacks" and trigger them after the command executes.
Here is the updated class with Output Parameter and Return Value support.

using Microsoft.Data.SqlClient;
using System.Data;

namespace NativeSql.DataAccess;

public class SqlFluentBuilder
{
    private readonly SqlConnection _connection;
    private readonly SqlCommand _command;
    private SqlTransaction? _transaction;
    
    // Store actions to run after execution to populate user variables
    private readonly List<Action> _postExecuteCallbacks = new();

    public SqlFluentBuilder(SqlConnection connection, string sqlText)
    {
        _connection = connection;
        _command = new SqlCommand(sqlText, connection);
    }

    // ... (Existing WithParameter methods) ...

    /// <summary>
    /// Adds an OUTPUT parameter and defines a callback to receive the value.
    /// </summary>
    /// <typeparam name="T">The C# type to map to (e.g., int, string)</typeparam>
    /// <param name="name">Parameter name (e.g. @Id)</param>
    /// <param name="callback">Action to run with the result (e.g. val => myId = val)</param>
    /// <param name="size">Required for String/Varchar output parameters</param>
    public SqlFluentBuilder WithOutputParameter<T>(string name, Action<T> callback, int size = -1)
    {
        var param = new SqlParameter(name, default(T))
        {
            Direction = ParameterDirection.Output,
            Size = size // Important for strings!
        };
        _command.Parameters.Add(param);

        // Register the callback to run later
        _postExecuteCallbacks.Add(() => 
        {
            if (param.Value != DBNull.Value && param.Value != null)
            {
                callback((T)Convert.ChangeType(param.Value, typeof(T)));
            }
        });

        return this;
    }

    /// <summary>
    /// Captures the "RETURN" value from a Stored Procedure (usually status codes like 0 or 1).
    /// </summary>
    public SqlFluentBuilder WithReturnValue(Action<int> callback)
    {
        var param = new SqlParameter
        {
            Direction = ParameterDirection.ReturnValue
        };
        _command.Parameters.Add(param);

        _postExecuteCallbacks.Add(() => 
        {
            if (param.Value != DBNull.Value && param.Value != null)
            {
                callback((int)param.Value);
            }
        });

        return this;
    }

    // --- Execution Methods (Updated) ---

    public async Task<int> ExecuteAsync()
    {
        await EnsureConnectionOpenAsync();
        var result = await _command.ExecuteNonQueryAsync();
        
        // Trigger all the output callbacks now that the command is done
        TriggerCallbacks();
        
        return result;
    }

    public async Task<IEnumerable<T>> QueryAsync<T>() where T : new()
    {
        await EnsureConnectionOpenAsync();
        var list = new List<T>();

        using var reader = await _command.ExecuteReaderAsync();
        while (await reader.ReadAsync())
        {
            list.Add(EntityMapper.Map<T>(reader));
        }
        
        // Even Selects can have output params (though rare)
        // Note: You must close the Reader before Output Params are available in ADO.NET
        reader.Close(); 
        TriggerCallbacks();

        return list;
    }
    
    // ... (Update QuerySingleAsync similarly) ...

    private void TriggerCallbacks()
    {
        foreach (var action in _postExecuteCallbacks)
        {
            action();
        }
    }

    // ... (Existing EnsureConnectionOpenAsync) ...
}

2. Usage Examples
Here is how you use the new syntax. It relies on C# Closures‚Äîthe library updates your local variables automatically.
Scenario A: Getting a New ID after Insert
This is the most common use case. You insert a row and want the IDENTITY ID back.

int newUserId = 0; // 1. Create a variable to hold the result

using var conn = new SqlConnection(connString);

await conn.Sql("INSERT INTO Users (Name) VALUES (@n); SET @newId = SCOPE_IDENTITY();")
          .WithParameter("@n", "Alice")
          // 2. Map the SQL param @newId to your C# variable 'newUserId'
          .WithOutputParameter<int>("@newId", val => newUserId = val) 
          .ExecuteAsync();

Console.WriteLine($"Created User with ID: {newUserId}");

Scenario B: Stored Procedures with multiple Outputs
Imagine a legacy SP that calculates stats and returns them via outputs.

/* SQL Definition:
   CREATE PROC sp_GetUserStats 
       @UserId INT, 
       @TotalLoginCount INT OUTPUT, 
       @LastLoginDate DATETIME OUTPUT
*/

C# Implementation:
int totalLogins = 0;
DateTime lastLogin = DateTime.MinValue;

await conn.Sql("sp_GetUserStats")
          .AsStoredProcedure()
          .WithParameter("@UserId", 55)
          .WithOutputParameter<int>("@TotalLoginCount", val => totalLogins = val)
          .WithOutputParameter<DateTime>("@LastLoginDate", val => lastLogin = val)
          .ExecuteAsync();

Console.WriteLine($"User logged in {totalLogins} times. Last: {lastLogin}");

Scenario C: Checking the Return Value (Status)
Stored procedures often return integers (0 = Success, 1 = Error).

int statusCode = -1;

await conn.Sql("sp_ProcessPayroll")
          .AsStoredProcedure()
          .WithReturnValue(code => statusCode = code)
          .ExecuteAsync();

if (statusCode == 0) Console.WriteLine("Success");
else Console.WriteLine("SP Failed");

Why this approach is robust
1. Safety: We handle DBNull inside the builder, so your application code doesn't crash if the DB returns null.
2. Reader Closing: In ADO.NET, Output Parameters are not populated until the SqlDataReader is explicitly closed. By calling TriggerCallbacks() after reader.Close() in QueryAsync, we prevent a very common and frustrating bug.
3. Readability: All logic stays in one fluent chain.

------
Would you like to tackle "Global Exception Logging" next? (We can wrap these executions so that if any SQL error occurs, it is automatically logged with the exact SQL query and parameters that caused it).

That's the final, and most critical, step for building a robust production-ready data access layer! A DAL must be resilient and transparent when failures occur.
We'll achieve this by introducing a Decorator Pattern‚Äîa wrapper that executes your fluent commands and automatically catches, logs, and rethrows exceptions, including the exact SQL text and parameters that failed.
Here is the implementation plan:
1. Define an Interface: Create IDataExecutor so the core logic can be decorated.
2. Core Implementation: The existing SqlFluentBuilder will implement this interface.
3. Decorator Class: Create LoggingDataExecutor to wrap the core, handle exceptions, and log details.
4. DI Update: Change the Dependency Injection setup to register the decorator.
1. üìù The Interface and Core Class Update
We need a common contract so the wrapper knows what methods to call.
A. Create IDataExecutor.cs

namespace NativeSql.DataAccess;

public interface IDataExecutor
{
    // Execution methods matching your current terminal methods
    Task<int> ExecuteNonQueryAsync();
    Task<T?> ExecuteScalarAsync<T>();
    Task<IEnumerable<T>> QueryAsync<T>() where T : new();
    IAsyncEnumerable<T> QueryStreamAsync<T>() where T : new();
    
    // Add methods to retrieve command details for logging
    string GetCommandText();
    IReadOnlyDictionary<string, object?> GetParameters();
}

B. Update SqlFluentBuilder.cs
Your SqlFluentBuilder must now implement IDataExecutor. We also need to add the methods to expose the command details.

// ... inside SqlFluentBuilder class ...

// Update the class definition
public class SqlFluentBuilder : IDataExecutor 
// ... rest of the class ...

// Implement the new interface methods
public string GetCommandText()
{
    return _command.CommandText;
}

public IReadOnlyDictionary<string, object?> GetParameters()
{
    var dict = new Dictionary<string, object?>();
    foreach(SqlParameter p in _command.Parameters)
    {
        // Don't log the direction/type; just the name and the value we sent.
        if (p.Direction != ParameterDirection.ReturnValue)
        {
            dict.Add(p.ParameterName, p.Value == DBNull.Value ? null : p.Value);
        }
    }
    return dict;
}

2. üõ°Ô∏è The Logging Decorator
This class wraps the SqlFluentBuilder and adds the exception handling logic without modifying the core execution code.

using Microsoft.Extensions.Logging;
using System.Text.Json; // Native library for easy object-to-string conversion

namespace NativeSql.DataAccess;

public class LoggingDataExecutor : IDataExecutor
{
    private readonly IDataExecutor _innerExecutor;
    private readonly ILogger<LoggingDataExecutor> _logger;
    
    // The decorator takes the core builder (IDataExecutor) and the logger
    public LoggingDataExecutor(IDataExecutor innerExecutor, ILogger<LoggingDataExecutor> logger)
    {
        _innerExecutor = innerExecutor;
        _logger = logger;
    }

    // --- Decorator Execution Methods ---

    public async Task<int> ExecuteNonQueryAsync() =>
        await ExecuteAndLog(async () => await _innerExecutor.ExecuteNonQueryAsync());

    public async Task<T?> ExecuteScalarAsync<T>() =>
        await ExecuteAndLog(async () => await _innerExecutor.ExecuteScalarAsync<T>());

    public async Task<IEnumerable<T>> QueryAsync<T>() where T : new() =>
        await ExecuteAndLog(async () => await _innerExecutor.QueryAsync<T>());

    // Note: Streaming needs special handling to yield control to the inner stream
    public IAsyncEnumerable<T> QueryStreamAsync<T>() where T : new()
    {
        // For streaming, we can't use a simple try/catch around the whole method; 
        // we wrap the inner enumerable for robust exception handling during iteration.
        return ExecuteAndLogStream<T>(() => _innerExecutor.QueryStreamAsync<T>());
    }

    // --- Core Logging Logic ---

    private async Task<T> ExecuteAndLog<T>(Func<Task<T>> func)
    {
        try
        {
            return await func();
        }
        catch (Exception ex)
        {
            LogExecutionError(ex);
            throw; // Rethrow the exception after logging
        }
    }

    private async IAsyncEnumerable<T> ExecuteAndLogStream<T>(Func<IAsyncEnumerable<T>> func)
    {
        try
        {
            await foreach (var item in func())
            {
                yield return item;
            }
        }
        catch (Exception ex)
        {
            // Log the error that occurred during the streaming iteration
            LogExecutionError(ex);
            throw; 
        }
    }

    private void LogExecutionError(Exception ex)
    {
        var sql = _innerExecutor.GetCommandText();
        var parameters = _innerExecutor.GetParameters();

        // Convert parameters to a readable JSON string using the native System.Text.Json
        var paramJson = JsonSerializer.Serialize(parameters);

        _logger.LogError(
            ex, 
            "SQL Execution Failed. Command: {SqlText}. Parameters: {Parameters}",
            sql, 
            paramJson);
    }
    
    // Required by the interface, but not used by the Decorator directly.
    public string GetCommandText() => _innerExecutor.GetCommandText();
    public IReadOnlyDictionary<string, object?> GetParameters() => _innerExecutor.GetParameters();
}


3. ‚öôÔ∏è Dependency Injection Update
We need to update the entry point of your library (ServiceCollectionExtensions.cs) to ensure the logger is injected, and the decorator wraps the concrete implementation.

using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging; // Required for ILogger

namespace NativeSql.DataAccess;

public static class ServiceCollectionExtensions
{
    public static IServiceCollection AddNativeSql(this IServiceCollection services, string connectionString)
    {
        services.AddSingleton(new ConnectionStringWrapper(connectionString));
        
        // Register the IDataExecutor interface pointing to the FluentBuilder
        // We use a factory to resolve the logger and connection string
        services.AddScoped<SqlFluentBuilder>(provider =>
        {
             var connStringWrapper = provider.GetRequiredService<ConnectionStringWrapper>();
             return new SqlFluentBuilder(connStringWrapper.Value); // Assuming you updated the ctor for DI
        });
        
        // Now register the DECORATOR to intercept the builder calls
        services.AddScoped<IDataExecutor>(provider =>
        {
            // The inner service is the concrete SqlFluentBuilder
            var innerBuilder = provider.GetRequiredService<SqlFluentBuilder>();
            var logger = provider.GetRequiredService<ILogger<LoggingDataExecutor>>();
            
            // Return the decorated version
            return new LoggingDataExecutor(innerBuilder, logger);
        });

        return services;
    }
}


Final Architecture Summary
Any component that consumes your DAL now depends on IDataExecutor. When ExecuteAsync() is called:
1. The call goes to the LoggingDataExecutor (the wrapper).
2. The wrapper calls the underlying SqlFluentBuilder (the core).
3. If the core throws a SqlException, the wrapper catches it.
4. The wrapper logs the entire context (SQL + Parameters) to your configured ILogger.
5. The wrapper rethrows the exception, maintaining the integrity of the call stack.
Your DAL is now complete with features, performance, and enterprise-grade resilience!
